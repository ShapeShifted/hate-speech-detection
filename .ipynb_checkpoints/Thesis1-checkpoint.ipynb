{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd8f4e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"./posts1352.csv\", encoding_errors= 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d6d0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_extra = [\"always\",\"want\",\"even\",\"still\",\"ever\",\"also\",\"already\",\"yet\",\"basically\",\"actually\",\"need\",\"please\",\"ago\",\"probable\",\"probably\",\"however\",\"instead\",\"quite\",\"nt\",\"na\",\"u\",\"gon\",\"lol\",\"im\",\"ca\",\"us\",\"cnt\",\"wo\",\"em\",\"etc\",\"ll\",\"aint\",\"r\",\"cant\",\"shouldnt\",\"wont\",\"lah\",\"dont\",\"never\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d0b5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1d2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.dropna()\n",
    "\n",
    "#df1.fillna(\"Zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c27ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qing5\\AppData\\Local\\Temp\\ipykernel_12968\\3973988239.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[\"Post\"] = df2[\"Post\"].apply(lambda x: sent_tokenize(x)) #this only \"tokenize\" post with multuple lines into sentences\n"
     ]
    }
   ],
   "source": [
    "df2[\"Post\"] = df2[\"Post\"].apply(lambda x: sent_tokenize(x)) #this only \"tokenize\" post with multuple lines into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf58ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "132d4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.explode('Post')\n",
    "\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b907e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Post</th>\n",
       "      <th>HateSpeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Race</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese are pigs!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Race</td>\n",
       "      <td>Indian</td>\n",
       "      <td>I don't like pajeets they smell like curry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Race</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Indians always smell stinky and weird, what is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Women are so emotional they can't handle anyth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Race</td>\n",
       "      <td>Malay</td>\n",
       "      <td>Malays are dependant on subsidiaries from the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>1349</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>You cannot build a temple in an area with majo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1350</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>Muslims should not enter temple, or they might...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1351</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Men that don't have job are useless piece of s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1352</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Women are dick machines.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1352</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Only want to suck and consume the biggest dick.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1638 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        No  Category SubCategory  \\\n",
       "0        1      Race     Chinese   \n",
       "1        2      Race      Indian   \n",
       "2        4      Race      Indian   \n",
       "3        5    Gender      Female   \n",
       "4        6      Race       Malay   \n",
       "...    ...       ...         ...   \n",
       "1633  1349  Religion    Buddhism   \n",
       "1634  1350  Religion    Buddhism   \n",
       "1635  1351    Gender        Male   \n",
       "1636  1352    Gender      Female   \n",
       "1637  1352    Gender      Female   \n",
       "\n",
       "                                                   Post  HateSpeech  \n",
       "0                                     Chinese are pigs!           1  \n",
       "1            I don't like pajeets they smell like curry           1  \n",
       "2     Indians always smell stinky and weird, what is...           1  \n",
       "3     Women are so emotional they can't handle anyth...           1  \n",
       "4     Malays are dependant on subsidiaries from the ...           1  \n",
       "...                                                 ...         ...  \n",
       "1633  You cannot build a temple in an area with majo...           1  \n",
       "1634  Muslims should not enter temple, or they might...           1  \n",
       "1635  Men that don't have job are useless piece of s...           1  \n",
       "1636                           Women are dick machines.           1  \n",
       "1637    Only want to suck and consume the biggest dick.           1  \n",
       "\n",
       "[1638 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b738e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory1</th>\n",
       "      <th>Post</th>\n",
       "      <th>HateSpeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Race</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese are pigs!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Race</td>\n",
       "      <td>Indian</td>\n",
       "      <td>I don't like pajeets they smell like curry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Race</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Indians always smell stinky and weird, what is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Women are so emotional they can't handle anyth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Race</td>\n",
       "      <td>Malay</td>\n",
       "      <td>Malays are dependant on subsidiaries from the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>1349</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>You cannot build a temple in an area with majo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>1350</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>Muslims should not enter temple, or they might...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>1351</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Men that don't have job are useless piece of s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>1352</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Women are dick machines.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>1352</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Only want to suck and consume the biggest dick.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1638 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        No  Category SubCategory1  \\\n",
       "0        1      Race      Chinese   \n",
       "1        2      Race       Indian   \n",
       "3        4      Race       Indian   \n",
       "4        5    Gender       Female   \n",
       "5        6      Race        Malay   \n",
       "...    ...       ...          ...   \n",
       "1971  1349  Religion     Buddhism   \n",
       "1972  1350  Religion     Buddhism   \n",
       "1973  1351    Gender         Male   \n",
       "1974  1352    Gender       Female   \n",
       "1975  1352    Gender       Female   \n",
       "\n",
       "                                                   Post  HateSpeech  \n",
       "0                                     Chinese are pigs!           1  \n",
       "1            I don't like pajeets they smell like curry           1  \n",
       "3     Indians always smell stinky and weird, what is...           1  \n",
       "4     Women are so emotional they can't handle anyth...           1  \n",
       "5     Malays are dependant on subsidiaries from the ...           1  \n",
       "...                                                 ...         ...  \n",
       "1971  You cannot build a temple in an area with majo...           1  \n",
       "1972  Muslims should not enter temple, or they might...           1  \n",
       "1973  Men that don't have job are useless piece of s...           1  \n",
       "1974                           Women are dick machines.           1  \n",
       "1975    Only want to suck and consume the biggest dick.           1  \n",
       "\n",
       "[1638 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77ccc2",
   "metadata": {},
   "source": [
    "## Skip here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bfeee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['HateSpeech'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Category'].value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "religion = df1[df1['Category']=='Religion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "religion['SubCategory1'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "religion['HateSpeech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "race= df1[df1['Category']=='Race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "race['SubCategory1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d31072",
   "metadata": {},
   "outputs": [],
   "source": [
    "race['HateSpeech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = df1[df1['Category']=='Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender['SubCategory1'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender['HateSpeech'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['HateSpeech'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba20c68",
   "metadata": {},
   "source": [
    "## Start at here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4522e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') #, disable=['parser', 'ner']) \n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords += stopword_extra\n",
    "\n",
    "negative_list = ['not','never','ain','aint','no','neither','nor','nt','cant','dont',\"cnt\",'wont',\"shouldnt\"]\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    #1. Generating the list of words in the tweet (hastags and other punctuations removed)\n",
    "    # .correct() is added to automatically correct typos and grammar errors in datasets\n",
    "    text_blob = TextBlob(text)\n",
    "    text = ' '.join(text_blob.words)\n",
    "    \n",
    "    # remove number\n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = text.replace('/',' ')\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "        \n",
    "    \n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    #keep tokens that are alphabet characters\n",
    "    text = [t for t in text if t.isalpha()]\n",
    "    \n",
    "    # replace the negation token\n",
    "    replacer  = AntonymReplacer()\n",
    "    text = replacer.replace_negations(text)\n",
    "    \n",
    "    # remove the stopwords\n",
    "    text = [i for i in text if i not in stopwords]\n",
    "       \n",
    "    # lemmatize the text\n",
    "    #text = lemmatization(text)\n",
    "    \n",
    "    #remove empty token\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatization(sent, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    doc = nlp(\" \".join(sent)) \n",
    "    texts_out = [token.lemma_ for token in doc if token.pos_ in allowed_postags]\n",
    "    return texts_out\n",
    "\n",
    "class AntonymReplacer(object):\n",
    "    def replace(self, word, pos=None):\n",
    "        antonyms = set()\n",
    "\n",
    "        for syn in wordnet.synsets(word, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def replace_negations(self, sent):\n",
    "        i, l = 0, len(sent)\n",
    "        words = []\n",
    "\n",
    "        while i < l:\n",
    "            word = sent[i]\n",
    "\n",
    "            if word in negative_list and i+1 < l:\n",
    "                ant = self.replace(sent[i+1])\n",
    "\n",
    "                if ant:\n",
    "                    words.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "\n",
    "            words.append(word)\n",
    "            i += 1\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c94685a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing row 100\n",
      "Preprocessing row 200\n",
      "Preprocessing row 300\n",
      "Preprocessing row 400\n",
      "Preprocessing row 500\n",
      "Preprocessing row 600\n",
      "Preprocessing row 700\n",
      "Preprocessing row 800\n",
      "Preprocessing row 900\n",
      "Preprocessing row 1000\n",
      "Preprocessing row 1100\n",
      "Preprocessing row 1200\n",
      "Preprocessing row 1300\n",
      "Preprocessing row 1400\n",
      "Preprocessing row 1500\n",
      "Preprocessing row 1600\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the input data\n",
    "cleaned_text = []\n",
    "counter = 1\n",
    "\n",
    "for text in df2[\"Post\"]:\n",
    "    if counter % 100 == 0:\n",
    "        print(f'Preprocessing row {counter}')\n",
    "    counter+=1\n",
    "    \n",
    "    cleaned_text.append(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "545f11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"PreprocessedToken\"] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21a1002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df2)):\n",
    "\n",
    "    if len(df2[\"PreprocessedToken\"][i]) == 0:\n",
    "        df2 = df2.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc1dc3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foreigners', 'know', 'kuala', 'lumpur', 'city', 'bedbugs']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dd2d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('posts1352_preprocessed_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "165ab37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Post</th>\n",
       "      <th>HateSpeech</th>\n",
       "      <th>PreprocessedToken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Race</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese are pigs!</td>\n",
       "      <td>1</td>\n",
       "      <td>[chinese, pigs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Race</td>\n",
       "      <td>Indian</td>\n",
       "      <td>I don't like pajeets they smell like curry</td>\n",
       "      <td>1</td>\n",
       "      <td>[like, pajeets, smell, like, curry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Race</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Indians always smell stinky and weird, what is...</td>\n",
       "      <td>1</td>\n",
       "      <td>[indians, smell, stinky, weird]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Women are so emotional they can't handle anyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>[women, emotional, handle, anything, keep, cry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Race</td>\n",
       "      <td>Malay</td>\n",
       "      <td>Malays are dependant on subsidiaries from the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[malays, dependant, subsidiaries, government]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>1349</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>You cannot build a temple in an area with majo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[build, temple, area, majority, muslims]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1350</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>Muslims should not enter temple, or they might...</td>\n",
       "      <td>1</td>\n",
       "      <td>[muslims, enter, temple, might, accidentaly, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1351</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Men that don't have job are useless piece of s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[men, job, useless, piece, sheet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1352</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Women are dick machines.</td>\n",
       "      <td>1</td>\n",
       "      <td>[women, dick, machines]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1352</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Only want to suck and consume the biggest dick.</td>\n",
       "      <td>1</td>\n",
       "      <td>[suck, consume, biggest, dick]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1618 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        No  Category SubCategory  \\\n",
       "0        1      Race     Chinese   \n",
       "1        2      Race      Indian   \n",
       "2        4      Race      Indian   \n",
       "3        5    Gender      Female   \n",
       "4        6      Race       Malay   \n",
       "...    ...       ...         ...   \n",
       "1633  1349  Religion    Buddhism   \n",
       "1634  1350  Religion    Buddhism   \n",
       "1635  1351    Gender        Male   \n",
       "1636  1352    Gender      Female   \n",
       "1637  1352    Gender      Female   \n",
       "\n",
       "                                                   Post  HateSpeech  \\\n",
       "0                                     Chinese are pigs!           1   \n",
       "1            I don't like pajeets they smell like curry           1   \n",
       "2     Indians always smell stinky and weird, what is...           1   \n",
       "3     Women are so emotional they can't handle anyth...           1   \n",
       "4     Malays are dependant on subsidiaries from the ...           1   \n",
       "...                                                 ...         ...   \n",
       "1633  You cannot build a temple in an area with majo...           1   \n",
       "1634  Muslims should not enter temple, or they might...           1   \n",
       "1635  Men that don't have job are useless piece of s...           1   \n",
       "1636                           Women are dick machines.           1   \n",
       "1637    Only want to suck and consume the biggest dick.           1   \n",
       "\n",
       "                                      PreprocessedToken  \n",
       "0                                       [chinese, pigs]  \n",
       "1                   [like, pajeets, smell, like, curry]  \n",
       "2                       [indians, smell, stinky, weird]  \n",
       "3     [women, emotional, handle, anything, keep, cry...  \n",
       "4         [malays, dependant, subsidiaries, government]  \n",
       "...                                                 ...  \n",
       "1633           [build, temple, area, majority, muslims]  \n",
       "1634  [muslims, enter, temple, might, accidentaly, c...  \n",
       "1635                  [men, job, useless, piece, sheet]  \n",
       "1636                            [women, dick, machines]  \n",
       "1637                     [suck, consume, biggest, dick]  \n",
       "\n",
       "[1618 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac45084",
   "metadata": {},
   "source": [
    "Making a similar one without removing the None category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582497e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Post\"] = df1[\"Post\"].apply(lambda x: sent_tokenize(x)) #this only \"tokenize\" post with multuple lines into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9509bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.explode('Post')\n",
    "\n",
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "793931af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing row 100\n",
      "Preprocessing row 200\n",
      "Preprocessing row 300\n",
      "Preprocessing row 400\n",
      "Preprocessing row 500\n",
      "Preprocessing row 600\n",
      "Preprocessing row 700\n",
      "Preprocessing row 800\n",
      "Preprocessing row 900\n",
      "Preprocessing row 1000\n",
      "Preprocessing row 1100\n",
      "Preprocessing row 1200\n",
      "Preprocessing row 1300\n",
      "Preprocessing row 1400\n",
      "Preprocessing row 1500\n",
      "Preprocessing row 1600\n",
      "Preprocessing row 1700\n",
      "Preprocessing row 1800\n",
      "Preprocessing row 1900\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the input data\n",
    "cleaned_text2 = []\n",
    "counter = 1\n",
    "\n",
    "for text in df1[\"Post\"]:\n",
    "    if counter % 100 == 0:\n",
    "        print(f'Preprocessing row {counter}')\n",
    "    counter+=1\n",
    "    cleaned_text2.append(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10b496e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"PreprocessedToken\"] = cleaned_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0634e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('posts1352_preprocessed_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a12da8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Post</th>\n",
       "      <th>HateSpeech</th>\n",
       "      <th>PreprocessedToken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Race</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Chinese are pigs!</td>\n",
       "      <td>1</td>\n",
       "      <td>[chinese, pig]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Race</td>\n",
       "      <td>Indian</td>\n",
       "      <td>I don't like pajeets they smell like curry</td>\n",
       "      <td>1</td>\n",
       "      <td>[parent, smell, carry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Israel is defending itself from Hamas</td>\n",
       "      <td>0</td>\n",
       "      <td>[defend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Race</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Indians always smell stinky and weird, what is...</td>\n",
       "      <td>1</td>\n",
       "      <td>[always, smell, sticky, weird]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Women are so emotional they can't handle anyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>[woman, emotional, handle, keep, cry, man, help]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>1349</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>You cannot build a temple in an area with majo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[build, muslim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>1350</td>\n",
       "      <td>Religion</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>Muslims should not enter temple, or they might...</td>\n",
       "      <td>1</td>\n",
       "      <td>[muslim, enter, temple, accidentally, convert,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>1351</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Male</td>\n",
       "      <td>Men that don't have job are useless piece of s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[man, job, useless, piece, sheet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>1352</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Women are dick machines.</td>\n",
       "      <td>1</td>\n",
       "      <td>[woman, machine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>1352</td>\n",
       "      <td>Gender</td>\n",
       "      <td>Female</td>\n",
       "      <td>Only want to suck and consume the biggest dick.</td>\n",
       "      <td>1</td>\n",
       "      <td>[want, suck, consume, big, dick]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1976 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        No  Category SubCategory  \\\n",
       "0        1      Race     Chinese   \n",
       "1        2      Race      Indian   \n",
       "2        3       NaN         NaN   \n",
       "3        4      Race      Indian   \n",
       "4        5    Gender      Female   \n",
       "...    ...       ...         ...   \n",
       "1971  1349  Religion    Buddhism   \n",
       "1972  1350  Religion    Buddhism   \n",
       "1973  1351    Gender        Male   \n",
       "1974  1352    Gender      Female   \n",
       "1975  1352    Gender      Female   \n",
       "\n",
       "                                                   Post  HateSpeech  \\\n",
       "0                                     Chinese are pigs!           1   \n",
       "1            I don't like pajeets they smell like curry           1   \n",
       "2                 Israel is defending itself from Hamas           0   \n",
       "3     Indians always smell stinky and weird, what is...           1   \n",
       "4     Women are so emotional they can't handle anyth...           1   \n",
       "...                                                 ...         ...   \n",
       "1971  You cannot build a temple in an area with majo...           1   \n",
       "1972  Muslims should not enter temple, or they might...           1   \n",
       "1973  Men that don't have job are useless piece of s...           1   \n",
       "1974                           Women are dick machines.           1   \n",
       "1975    Only want to suck and consume the biggest dick.           1   \n",
       "\n",
       "                                      PreprocessedToken  \n",
       "0                                        [chinese, pig]  \n",
       "1                                [parent, smell, carry]  \n",
       "2                                              [defend]  \n",
       "3                        [always, smell, sticky, weird]  \n",
       "4      [woman, emotional, handle, keep, cry, man, help]  \n",
       "...                                                 ...  \n",
       "1971                                    [build, muslim]  \n",
       "1972  [muslim, enter, temple, accidentally, convert,...  \n",
       "1973                  [man, job, useless, piece, sheet]  \n",
       "1974                                   [woman, machine]  \n",
       "1975                   [want, suck, consume, big, dick]  \n",
       "\n",
       "[1976 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0640dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'always',\n",
       " 'want',\n",
       " 'even',\n",
       " 'still',\n",
       " 'ever',\n",
       " 'also',\n",
       " 'already',\n",
       " 'yet',\n",
       " 'basically',\n",
       " 'actually',\n",
       " 'need',\n",
       " 'please',\n",
       " 'ago',\n",
       " 'probable',\n",
       " 'probably',\n",
       " 'however',\n",
       " 'instead',\n",
       " 'quite',\n",
       " 'nt',\n",
       " 'na',\n",
       " 'u',\n",
       " 'gon',\n",
       " 'ca',\n",
       " 'wo',\n",
       " 'll',\n",
       " 'aint',\n",
       " 'r',\n",
       " 'cant',\n",
       " 'shouldnt',\n",
       " 'wont',\n",
       " 'lah',\n",
       " 'dont',\n",
       " 'never']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11e677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
